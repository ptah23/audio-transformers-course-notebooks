{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71d8085-d60a-4c11-9234-d96b9b956d8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Required Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7af3e-a5a1-4e75-aa6b-1b90cee3d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c7b34-f4ef-4f3f-9392-3e59f35ea4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5a460-57c9-4570-8259-f87ac599a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd879e0-93df-4d7e-bf51-75537497cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b3c6a-68fe-4f1a-ba3d-94a17fd1dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5b3ca-dd52-4102-a2cb-32b533411389",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73ed9d-d8f2-4e44-83c6-c224e7b65665",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34a89c-33d0-4f5a-9dfb-9aef926f1d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d357e8f-9eae-4d32-bf79-6434a983cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a17537-b5a5-4120-90be-90fb377d5a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf67c0e-1e07-48ba-aa58-263175e1db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a0e06-f352-416f-a989-a4855c237c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7eb83-e61f-42cd-b709-ba40ded52297",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be53d9e-9949-496f-bf00-5253689e777d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e961ec3-9b9b-4fa7-95c5-5d1b279f1d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9828ed61c7874c1fbefbd01ae832e818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# have to login to access speech-commands dataset\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f938f64-db7d-4da4-b065-d849aedf1afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mptah23\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c5f4f3-d526-4783-9c9d-3d37b7dc1bae",
   "metadata": {},
   "source": [
    "# Build a music genre classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe657c9f-d9b7-404e-bfdc-366a53535e44",
   "metadata": {},
   "source": [
    "## Pre-trained models and datasets for audio classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a26c5-ed50-4288-8de1-0dcd23cb45d5",
   "metadata": {},
   "source": [
    "#### Minds-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746d62a3-7f84-4e25-903b-86317a541579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset minds14 (/root/.cache/huggingface/datasets/PolyAI___minds14/en-AU/1.0.0/65c7e0f3be79e18a6ffaf879a083daf706312d421ac90d25718459cbf3c42696)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123e5729-0475-47c7-8d98-acfe5b34e2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d687a310d044668b9d69f108f2951a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/2.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c562b85ce9ed41629347c1a420d4727e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e87bc693e2b4795b9f4b5a9345b41e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"audio-classification\", model=\"anton-l/xtreme_s_xlsr_300m_minds14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75f7d2-e515-4e4f-a2ce-9e16f8180a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(minds[0][\"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263e1a8-f818-4992-9ace-08a6fd93ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(minds[0][\"path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d249b-882e-43a4-bc62-4e037e627986",
   "metadata": {},
   "source": [
    "#### Speech commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1356475-5921-4e46-8af8-4307ce9fd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_commands = load_dataset(\"speech_commands\", \"v0.02\", split=\"validation\", streaming=True)\n",
    "sample = next(iter(speech_commands))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d9f6d-6cdc-4a0d-97a0-84ed970d2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(sample[\"audio\"][\"array\"], rate=sample[\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149cb25-dd6b-40c8-97a2-9df65484d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"audio-classification\", model=\"MIT/ast-finetuned-speech-commands-v2\")\n",
    "classifier(sample[\"audio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18775a3c-0eda-4497-9a8c-7b9edac9a099",
   "metadata": {},
   "source": [
    "#### FLEURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c2a5a-6ff9-4937-8191-47662f70988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fleurs = load_dataset(\"google/fleurs\", \"all\", split=\"validation\", streaming=True)\n",
    "sample = next(iter(fleurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76c639-94ef-457c-8f3e-6adec44aab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f11da-12cf-4a69-b64e-c320ac303943",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=sample[\"audio\"][\"array\"], rate=sample[\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05d40f-8a65-45c2-8d81-ccb48e829829",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"audio-classification\", model=\"sanchit-gandhi/whisper-medium-fleurs-lang-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9cd72-9624-47bb-ad56-dda382596bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(sample[\"audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60259748-8805-424a-90f3-8ad1c9d7dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ashraq/esc50\", split=\"train\", streaming=True)\n",
    "sample= next(iter(dataset))\n",
    "audio_sample = sample[\"audio\"][\"array\"]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897858e-58e3-4f1b-9253-5116cd190d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=audio_sample, rate=44_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad94a31-716c-4320-b23b-2df1a4b8aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels=[\"Sound of a dog\", \"Sound of vacuum cleaner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcfadb-6a49-468c-8a66-e6a1ba47e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/clap-htsat-unfused\")\n",
    "classifier(audio_sample, candidate_labels=candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659cb4d2-1015-4f2f-99b5-2edaff014a74",
   "metadata": {},
   "source": [
    "## Fine-tuning a model for music classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93161c2f-11be-4353-b0f0-83500c9b5b7d",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2595ec9-39d0-42e5-a5c9-bd6df2b8c92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration all\n",
      "Reusing dataset gtzan (/root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/8bd0e23c2d9b2be30d36bc6834319772dff22a3bd28527996612386cef003910)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee91c27a3385497ca759563a731f74c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan = load_dataset(\"marsyas/gtzan\", \"all\")\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea915295-6b56-40e1-ac62-1783180076c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/8bd0e23c2d9b2be30d36bc6834319772dff22a3bd28527996612386cef003910/cache-52d2398c8e4ac745.arrow and /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/8bd0e23c2d9b2be30d36bc6834319772dff22a3bd28527996612386cef003910/cache-3bcc56e346e4d81c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan = gtzan[\"train\"].train_test_split(seed=42, shuffle=True, test_size=0.1)\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "856330fe-7076-4782-a39e-242ab827e39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       "  'array': array([ 0.10720825,  0.16122437,  0.28585815, ..., -0.22924805,\n",
       "         -0.20629883, -0.11334229], dtype=float32),\n",
       "  'sampling_rate': 22050},\n",
       " 'genre': 7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be17e20c-f0f7-4814-bd3a-e5ac5abbb30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pop'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label_fn = gtzan[\"train\"].features[\"genre\"].int2str\n",
    "id2label_fn(gtzan[\"train\"][0][\"genre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e492ba-42d5-4c26-a4e5-0195476738f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "# def generate_audio():\n",
    "#     example = gtzan[\"train\"].shuffle()[0]\n",
    "#     audio = example[\"audio\"]\n",
    "#     return (\n",
    "#         audio[\"sampling_rate\"],\n",
    "#         audio[\"array\"],\n",
    "#     ), id2label_fn(example[\"genre\"])\n",
    "\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     with gr.Column():\n",
    "#         for _ in range(4):\n",
    "#             audio, label = generate_audio()\n",
    "#             output = gr.Audio(audio, label=label)\n",
    "\n",
    "# demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020d07e-02af-42bb-b46c-8e794b3fd797",
   "metadata": {},
   "source": [
    "### Picking a pretrained model for audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d1904b-4171-497d-8a98-6d65f4db3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "model_id = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_id, do_normalize=True, return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecb64a7c-72ab-4b18-845e-12ef64d78f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = feature_extractor.sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8560cd31-de41-4dac-8f85-b459ed45388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "gtzan = gtzan.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3649146d-23d2-47e5-a9d8-929f23ea4000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       "  'array': array([ 0.0873509 ,  0.20183384,  0.4790867 , ..., -0.18743178,\n",
       "         -0.23294401, -0.13517427], dtype=float32),\n",
       "  'sampling_rate': 16000},\n",
       " 'genre': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbcfd076-4935-4e9d-9c7c-087839631e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.000185, Variance: 0.0493\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample = gtzan[\"train\"][0][\"audio\"]\n",
    "print(f\"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0da029b-ac92-4287-a28b-1d3e388b913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs keys: ['input_values']\n"
     ]
    }
   ],
   "source": [
    "inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\")\n",
    "print(f\"inputs keys: {list(inputs.keys())}\")\n",
    "                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae69167-3bd2-4c0b-9ef9-ed2b65cb1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 30.0\n",
    "def preprocess_function(examples):\n",
    "    audio_arrays=[x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=int(feature_extractor.sampling_rate * max_duration), truncation=True, return_attention_mask=False)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ef9c24-6592-4506-966b-baae55a70c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f21825bae74e7ca12e929ca0ab4d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b60d1d8a1c4ebb88d36ac649dc6a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['genre', 'input_values'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['genre', 'input_values'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan_encoded = gtzan.map( preprocess_function, remove_columns=[\"audio\", \"file\"], batched=True, num_proc=1)\n",
    "gtzan_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4722e9c1-d3bd-4850-95f2-5ddc748f5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan_encoded = gtzan_encoded.rename_column(\"genre\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d76a3950-5da8-4963-a8b2-edddb6666436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pop'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = { str(i): id2label_fn(i) for i in range(len(gtzan_encoded[\"train\"].features[\"label\"].names))}\n",
    "label2id = {v: k for k,v in id2label.items()}\n",
    "id2label[\"7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dca46d3-ed52-4a43-80a7-422c18b606bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ASTForAudioClassification were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
      "- classifier.dense.weight: found shape torch.Size([527, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n",
      "- classifier.dense.bias: found shape torch.Size([527]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(model_id, num_labels=num_labels, label2id=label2id, id2label=id2label, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14d72f51-07a2-4ea8-887f-d984f959c7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=huggingface-audio-course\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "model_name = model_id.split(\"/\")[-1]\n",
    "batch_size=2\n",
    "gradient_accumulation_steps=4\n",
    "num_train_epochs=20\n",
    "%env WANDB_PROJECT=huggingface-audio-course\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-gtzan\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec68d892-0e7f-4d8a-b7d9-a6630cd1cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3acf251-5a02-41ae-9686-618291830cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/ast-finetuned-audioset-10-10-0.4593-finetuned-gtzan is already a clone of https://huggingface.co/ptah23/ast-finetuned-audioset-10-10-0.4593-finetuned-gtzan. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2240' max='2240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2240/2240 43:52, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.956900</td>\n",
       "      <td>0.646722</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.589479</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.453600</td>\n",
       "      <td>0.407001</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.381224</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.166065</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.482241</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.500029</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.407390</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.476858</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.374332</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.367320</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.395194</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.370972</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.346037</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348113</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347324</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349066</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350675</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354846</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2240, training_loss=0.1367254428033318, metrics={'train_runtime': 2634.3954, 'train_samples_per_second': 6.825, 'train_steps_per_second': 0.85, 'total_flos': 1.2134672243018957e+18, 'train_loss': 0.1367254428033318, 'epoch': 19.91})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=gtzan_encoded[\"train\"],\n",
    "    eval_dataset=gtzan_encoded[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")\n",
    "trainer.train()\n",
    "#trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "239c0b02-3cf8-493a-8b9b-1d0b6630951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a65239c4e2417cb64de07677a1d29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/ptah23/ast-finetuned-audioset-10-10-0.4593-finetuned-gtzan\n",
      "   91bb306..c1d3e49  main -> main\n",
      "\n",
      "To https://huggingface.co/ptah23/ast-finetuned-audioset-10-10-0.4593-finetuned-gtzan\n",
      "   c1d3e49..49a7388  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/ptah23/ast-finetuned-audioset-10-10-0.4593-finetuned-gtzan/commit/c1d3e499b6653268edfeeeade1b335b5614d9c5c'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"marsyas/gtzan\",\n",
    "    \"dataset\": \"GTZAN\",\n",
    "    \"model_name\": f\"{model_name}-finetuned-gtzan\",\n",
    "    \"finetuned_from\": model_id,\n",
    "    \"tasks\": \"audio-classification\",\n",
    "}\n",
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fc0b9-beba-462c-9ccd-2254863fa4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
